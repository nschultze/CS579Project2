{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the CSV file\n",
    "csv_filename = r'Taxi_Trips__2013-2023__20240417.csv'\n",
    "\n",
    "# Read data from the CSV file, excluding rows where \"Trip Miles\" is 0\n",
    "data = []\n",
    "with open(csv_filename, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row['Trip Miles'] != '0':\n",
    "            data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data[:10]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the Data by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data:\n",
    "    # Initialize a defaultdict to count taxi rides by month\n",
    "    month_counts = defaultdict(int)\n",
    "    \n",
    "    # Extract month from trip_start_timestamp for each record and count occurrences\n",
    "    for record in data:\n",
    "        start_timestamp = record.get(\"Trip Start Timestamp\", \"\")\n",
    "        if start_timestamp:\n",
    "            start_date = datetime.strptime(start_timestamp, \"%m/%d/%Y %I:%M:%S %p\")\n",
    "            month = start_date.month\n",
    "            month_counts[month] += 1\n",
    "\n",
    "    # Ensure counts for all months are included\n",
    "    for month in range(1, 13):\n",
    "        if month not in month_counts:\n",
    "            month_counts[month] = 0\n",
    "\n",
    "    # Sort the months chronologically\n",
    "    sorted_months = sorted(month_counts.keys())\n",
    "    \n",
    "    # Plot the bar graph\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.bar(sorted_months, [month_counts[month] for month in sorted_months])\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Number of Taxi Rides\")\n",
    "    plt.title(\"Distribution of Taxi Rides by Month\")\n",
    "    plt.xticks(range(1, 13), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "    \n",
    "    # Display the bar graph\n",
    "    plt.show()\n",
    "    \n",
    "    # Create the table data for month distribution\n",
    "    month_table_data = [['Month', 'Taxi Rides']]\n",
    "    for month in sorted_months:\n",
    "        month_table_data.append([datetime.strptime(str(month), \"%m\").strftime(\"%B\"), month_counts[month]])\n",
    "    \n",
    "    # Convert table data to a DataFrame for month distribution\n",
    "    month_df = pd.DataFrame(month_table_data[1:], columns=month_table_data[0])\n",
    "    \n",
    "    # Display the month distribution DataFrame\n",
    "    print(\"Month Distribution:\")\n",
    "    print(month_df)\n",
    "    \n",
    "    # Plot the table for month distribution\n",
    "    fig, ax = plt.subplots(figsize=(7, 3))\n",
    "    ax.axis('off')  # Turn off axis for the table\n",
    "    month_table = ax.table(cellText=month_df.values, colLabels=month_df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2])\n",
    "    month_table.auto_set_font_size(False)\n",
    "    month_table.set_fontsize(12)\n",
    "    month_table.scale(1.5, 1.5)  # Adjust table size\n",
    "    plt.show()\n",
    "    \n",
    "    # Construct a directed graph from pickup and dropoff locations\n",
    "    G = nx.DiGraph()\n",
    "    for record in data:\n",
    "        pickup_location = record[\"Pickup Community Area\"]\n",
    "        dropoff_location = record[\"Dropoff Community Area\"]\n",
    "        if pickup_location != dropoff_location:\n",
    "            G.add_edge(pickup_location, dropoff_location)\n",
    "    \n",
    "    # Calculate degree centrality\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    \n",
    "    # Calculate betweenness centrality\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    \n",
    "    # Calculate PageRank\n",
    "    pagerank = nx.pagerank(G)\n",
    "    \n",
    "    # Calculate clustering coefficient\n",
    "    clustering_coefficient = nx.clustering(G)\n",
    "    \n",
    "    # Create the table data for network metrics\n",
    "    network_metrics_table_data = [['Node', 'Degree Centrality', 'Betweenness Centrality', 'PageRank', 'Clustering Coefficient']]\n",
    "    for node in G.nodes():\n",
    "        network_metrics_table_data.append([node, degree_centrality.get(node, 0), betweenness_centrality.get(node, 0), pagerank.get(node, 0), clustering_coefficient.get(node, 0)])\n",
    "    \n",
    "    # Convert table data to a DataFrame for network metrics\n",
    "    network_metrics_df = pd.DataFrame(network_metrics_table_data[1:], columns=network_metrics_table_data[0])\n",
    "    \n",
    "    # Display the network metrics DataFrame\n",
    "    print(\"Network Metrics:\")\n",
    "    print(network_metrics_df)\n",
    "    \n",
    "    # Plot the table for network metrics\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.axis('off')  # Turn off axis for the table\n",
    "    network_metrics_table = ax.table(cellText=network_metrics_df.values, colLabels=network_metrics_df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    network_metrics_table.auto_set_font_size(False)\n",
    "    network_metrics_table.set_fontsize(12)\n",
    "    network_metrics_table.scale(1.5, 1.5)  # Adjust table size\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the Data by Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data:\n",
    "    # Initialize a defaultdict to count taxi rides by season\n",
    "    season_counts = defaultdict(int)\n",
    "    \n",
    "    # Map each month to its corresponding season\n",
    "    month_to_season = {\n",
    "        1: 'Winter', 2: 'Winter', 3: 'Spring',\n",
    "        4: 'Spring', 5: 'Spring', 6: 'Summer',\n",
    "        7: 'Summer', 8: 'Summer', 9: 'Fall',\n",
    "        10: 'Fall', 11: 'Fall', 12: 'Winter'\n",
    "    }\n",
    "    \n",
    "    # Extract month from trip_start_timestamp for each record and count occurrences by season\n",
    "    for record in data:\n",
    "        start_timestamp = record.get(\"Trip Start Timestamp\", \"\")\n",
    "        if start_timestamp:\n",
    "            start_date = datetime.strptime(start_timestamp, \"%m/%d/%Y %I:%M:%S %p\")\n",
    "            month = start_date.month\n",
    "            season = month_to_season[month]\n",
    "            season_counts[season] += 1\n",
    "\n",
    "    # Plot the bar graph for distribution of taxi rides by season\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(season_counts.keys(), season_counts.values())\n",
    "    plt.xlabel(\"Season\")\n",
    "    plt.ylabel(\"Number of Taxi Rides\")\n",
    "    plt.title(\"Distribution of Taxi Rides by Season\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Create the table data for distribution of taxi rides by season\n",
    "    season_table_data = [['Season', 'Taxi Rides']]\n",
    "    for season, count in season_counts.items():\n",
    "        season_table_data.append([season, count])\n",
    "    \n",
    "    # Convert table data to a DataFrame for distribution of taxi rides by season\n",
    "    season_df = pd.DataFrame(season_table_data[1:], columns=season_table_data[0])\n",
    "    \n",
    "    # Display the DataFrame for distribution of taxi rides by season\n",
    "    print(\"Taxi Rides by Season:\")\n",
    "    print(season_df)\n",
    "    \n",
    "    # Plot the table for distribution of taxi rides by season\n",
    "    fig, ax = plt.subplots(figsize=(7, 3))\n",
    "    ax.axis('off')  # Turn off axis for the table\n",
    "    season_table = ax.table(cellText=season_df.values, colLabels=season_df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2])\n",
    "    season_table.auto_set_font_size(False)\n",
    "    season_table.set_fontsize(12)\n",
    "    season_table.scale(1.5, 1.5)  # Adjust table size\n",
    "    plt.show()\n",
    "    \n",
    "    # Construct a directed graph from pickup and dropoff locations\n",
    "    G = nx.DiGraph()\n",
    "    for record in data:\n",
    "        pickup_location = record[\"Pickup Community Area\"]\n",
    "        dropoff_location = record[\"Dropoff Community Area\"]\n",
    "        if pickup_location != dropoff_location:\n",
    "            G.add_edge(pickup_location, dropoff_location)\n",
    "    \n",
    "    # Calculate degree centrality\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    \n",
    "    # Calculate betweenness centrality\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    \n",
    "    # Calculate PageRank\n",
    "    pagerank = nx.pagerank(G)\n",
    "    \n",
    "    # Calculate clustering coefficient\n",
    "    clustering_coefficient = nx.clustering(G)\n",
    "    \n",
    "    # Create the table data for network metrics\n",
    "    network_metrics_table_data = [['Node', 'Degree Centrality', 'Betweenness Centrality', 'PageRank', 'Clustering Coefficient']]\n",
    "    for node in G.nodes():\n",
    "        network_metrics_table_data.append([node, degree_centrality.get(node, 0), betweenness_centrality.get(node, 0), pagerank.get(node, 0), clustering_coefficient.get(node, 0)])\n",
    "    \n",
    "    # Convert table data to a DataFrame for network metrics\n",
    "    network_metrics_df = pd.DataFrame(network_metrics_table_data[1:], columns=network_metrics_table_data[0])\n",
    "    \n",
    "    # Display the network metrics DataFrame\n",
    "    print(\"Network Metrics:\")\n",
    "    print(network_metrics_df)\n",
    "    \n",
    "    # Plot the table for network metrics\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.axis('off')  # Turn off axis for the table\n",
    "    network_metrics_table = ax.table(cellText=network_metrics_df.values, colLabels=network_metrics_df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    network_metrics_table.auto_set_font_size(False)\n",
    "    network_metrics_table.set_fontsize(12)\n",
    "    network_metrics_table.scale(1.5, 1.5)  # Adjust table size\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the Data by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data:\n",
    "    # Extract year from trip_start_timestamp for each record and count occurrences by year\n",
    "    year_counts = defaultdict(int)\n",
    "    all_years = range(2013, 2024)  # Define the range of years you want to consider\n",
    "    \n",
    "    for record in data:\n",
    "        start_timestamp = record.get(\"Trip Start Timestamp\", \"\")\n",
    "        if start_timestamp:\n",
    "            start_date = datetime.strptime(start_timestamp, \"%m/%d/%Y %I:%M:%S %p\")\n",
    "            year = start_date.year\n",
    "            year_counts[year] += 1\n",
    "\n",
    "    # Ensure all years are included in the counts\n",
    "    for year in all_years:\n",
    "        year_counts[year] = year_counts.get(year, 0)\n",
    "\n",
    "    # Plot the bar graph for distribution of taxi rides by year\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(year_counts.keys(), year_counts.values())\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Number of Taxi Rides\")\n",
    "    plt.title(\"Distribution of Taxi Rides by Year\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Create the table data for distribution of taxi rides by year\n",
    "    year_table_data = [['Year', 'Taxi Rides']]\n",
    "    for year in sorted(all_years):\n",
    "        year_table_data.append([year, year_counts[year]])\n",
    "    \n",
    "    # Convert table data to a DataFrame for distribution of taxi rides by year\n",
    "    year_df = pd.DataFrame(year_table_data[1:], columns=year_table_data[0])\n",
    "    \n",
    "    # Display the DataFrame for distribution of taxi rides by year\n",
    "    print(\"Taxi Rides by Year:\")\n",
    "    print(year_df)\n",
    "    \n",
    "    # Plot the table for distribution of taxi rides by year\n",
    "    fig, ax = plt.subplots(figsize=(7, 3))\n",
    "    ax.axis('off')  # Turn off axis for the table\n",
    "    year_table = ax.table(cellText=year_df.values, colLabels=year_df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2])\n",
    "    year_table.auto_set_font_size(False)\n",
    "    year_table.set_fontsize(12)\n",
    "    year_table.scale(1.5, 1.5)  # Adjust table size\n",
    "    plt.show()\n",
    "    \n",
    "    # Construct a directed graph from pickup and dropoff locations\n",
    "    G = nx.DiGraph()\n",
    "    for record in data:\n",
    "        pickup_location = record[\"Pickup Community Area\"]\n",
    "        dropoff_location = record[\"Dropoff Community Area\"]\n",
    "        if pickup_location != dropoff_location:\n",
    "            G.add_edge(pickup_location, dropoff_location)\n",
    "    \n",
    "    # Calculate degree centrality\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    \n",
    "    # Calculate betweenness centrality\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    \n",
    "    # Calculate PageRank\n",
    "    pagerank = nx.pagerank(G)\n",
    "    \n",
    "    # Calculate clustering coefficient\n",
    "    clustering_coefficient = nx.clustering(G)\n",
    "    \n",
    "    # Create the table data for network metrics\n",
    "    network_metrics_table_data = [['Node', 'Degree Centrality', 'Betweenness Centrality', 'PageRank', 'Clustering Coefficient']]\n",
    "    for node in G.nodes():\n",
    "        network_metrics_table_data.append([node, degree_centrality.get(node, 0), betweenness_centrality.get(node, 0), pagerank.get(node, 0), clustering_coefficient.get(node, 0)])\n",
    "    \n",
    "    # Convert table data to a DataFrame for network metrics\n",
    "    network_metrics_df = pd.DataFrame(network_metrics_table_data[1:], columns=network_metrics_table_data[0])\n",
    "    \n",
    "    # Display the network metrics DataFrame\n",
    "    print(\"Network Metrics:\")\n",
    "    print(network_metrics_df)\n",
    "    \n",
    "    # Plot the table for network metrics\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.axis('off')  # Turn off axis for the table\n",
    "    network_metrics_table = ax.table(cellText=network_metrics_df.values, colLabels=network_metrics_df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    network_metrics_table.auto_set_font_size(False)\n",
    "    network_metrics_table.set_fontsize(12)\n",
    "    network_metrics_table.scale(1.5, 1.5)  # Adjust table size\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting by Trip Length by Miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data:\n",
    "    # Calculate trip lengths and count the number of taxi rides for each trip length interval\n",
    "    trip_length_counts = {}\n",
    "    for record in data:\n",
    "        trip_miles = record.get(\"Trip Miles\", None)\n",
    "        \n",
    "        # Check if trip miles is not empty and is a valid number\n",
    "        if trip_miles is not None and trip_miles.replace('.', '', 1).isdigit():\n",
    "            try:\n",
    "                trip_length = min(float(trip_miles), 20)  # Convert trip miles to float and limit to maximum 20\n",
    "                \n",
    "                # Define trip length intervals (e.g., every 1 mile)\n",
    "                interval = 1\n",
    "                trip_length_interval = int(trip_length / interval) * interval\n",
    "                \n",
    "                # Handle trips over 20 miles\n",
    "                if trip_length > 20:\n",
    "                    trip_length_interval = \"20+\"\n",
    "                \n",
    "                # Accumulate counts within each trip length interval\n",
    "                trip_length_counts[trip_length_interval] = trip_length_counts.get(trip_length_interval, 0) + 1\n",
    "            except ValueError:\n",
    "                # Handle any parsing errors\n",
    "                print(\"Error parsing trip miles for record:\", record)\n",
    "    \n",
    "    # Plot the bar graph for distribution of taxi rides by trip length\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(trip_length_counts.keys(), trip_length_counts.values(), width=0.8, color='blue')  # Adjust width and color as needed\n",
    "    plt.xlabel(\"Trip Length (miles)\")\n",
    "    plt.ylabel(\"Number of Taxi Rides\")\n",
    "    plt.title(\"Distribution of Taxi Rides by Trip Length\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Create the table data for distribution of taxi rides by trip length\n",
    "    trip_length_table_data = [['Trip Length (miles)', 'Taxi Rides']]\n",
    "    for trip_length, count in sorted(trip_length_counts.items()):\n",
    "        trip_length_table_data.append([trip_length, count])\n",
    "    \n",
    "    # Convert table data to a DataFrame for distribution of taxi rides by trip length\n",
    "    trip_length_df = pd.DataFrame(trip_length_table_data[1:], columns=trip_length_table_data[0])\n",
    "    \n",
    "    # Display the DataFrame for distribution of taxi rides by trip length\n",
    "    print(\"Taxi Rides by Trip Length:\")\n",
    "    print(trip_length_df)\n",
    "    \n",
    "    # Plot the table for distribution of taxi rides by trip length\n",
    "    fig, ax = plt.subplots(figsize=(7, 3))\n",
    "    ax.axis('off')  # Turn off axis for the table\n",
    "    trip_length_table = ax.table(cellText=trip_length_df.values, colLabels=trip_length_df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2])\n",
    "    trip_length_table.auto_set_font_size(False)\n",
    "    trip_length_table.set_fontsize(12)\n",
    "    trip_length_table.scale(1.5, 1.5)  # Adjust table size\n",
    "    plt.show()\n",
    "    \n",
    "    # Construct a directed graph from pickup and dropoff locations\n",
    "    G = nx.DiGraph()\n",
    "    for record in data:\n",
    "        pickup_location = record[\"Pickup Community Area\"]\n",
    "        dropoff_location = record[\"Dropoff Community Area\"]\n",
    "        if pickup_location != dropoff_location:\n",
    "            G.add_edge(pickup_location, dropoff_location)\n",
    "    \n",
    "    # Calculate degree centrality\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    \n",
    "    # Calculate betweenness centrality\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    \n",
    "    # Calculate PageRank\n",
    "    pagerank = nx.pagerank(G)\n",
    "    \n",
    "    # Calculate clustering coefficient\n",
    "    clustering_coefficient = nx.clustering(G)\n",
    "    \n",
    "    # Create the table data for network metrics\n",
    "    network_metrics_table_data = [['Node', 'Degree Centrality', 'Betweenness Centrality', 'PageRank', 'Clustering Coefficient']]\n",
    "    for node in G.nodes():\n",
    "        network_metrics_table_data.append([node, degree_centrality.get(node, 0), betweenness_centrality.get(node, 0), pagerank.get(node, 0), clustering_coefficient.get(node, 0)])\n",
    "    \n",
    "    # Convert table data to a DataFrame for network metrics\n",
    "    network_metrics_df = pd.DataFrame(network_metrics_table_data[1:], columns=network_metrics_table_data[0])\n",
    "    \n",
    "    # Display the network metrics DataFrame\n",
    "    print(\"Network Metrics:\")\n",
    "    print(network_metrics_df)\n",
    "    \n",
    "    # Plot the table for network metrics\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.axis('off')  # Turn off axis for the table\n",
    "    network_metrics_table = ax.table(cellText=network_metrics_df.values, colLabels=network_metrics_df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    network_metrics_table.auto_set_font_size(False)\n",
    "    network_metrics_table.set_fontsize(12)\n",
    "    network_metrics_table.scale(1.5, 1.5)  # Adjust table size\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting by Trip Start Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out records with missing or invalid trip start timestamp\n",
    "data = [record for record in data if record.get(\"Trip Start Timestamp\")]\n",
    "\n",
    "if data:\n",
    "    # Sort the data by the trip start timestamp\n",
    "    data.sort(key=lambda x: datetime.strptime(x[\"Trip Start Timestamp\"], \"%m/%d/%Y %I:%M:%S %p\"))\n",
    "    \n",
    "    # Count the number of taxi rides for each trip start hour\n",
    "    trip_start_hour_counts = {}\n",
    "    for record in data:\n",
    "        trip_start_time = datetime.strptime(record[\"Trip Start Timestamp\"], \"%m/%d/%Y %I:%M:%S %p\")\n",
    "        trip_start_hour = trip_start_time.hour\n",
    "        trip_start_hour_counts[trip_start_hour] = trip_start_hour_counts.get(trip_start_hour, 0) + 1\n",
    "    \n",
    "    # Plot the data as a bar graph\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(trip_start_hour_counts.keys(), trip_start_hour_counts.values(), width=0.5)\n",
    "    plt.xlabel(\"Hour of the Day (Start Time)\")\n",
    "    plt.ylabel(\"Number of Taxi Rides\")\n",
    "    plt.title(\"Distribution of Taxi Rides by Hour of the Day (Start Time)\")\n",
    "    plt.xticks(range(24))\n",
    "    plt.show()\n",
    "    \n",
    "    # Create the table data for distribution of taxi rides by trip start hour\n",
    "    trip_start_hour_table_data = [['Hour of the Day (Start Time)', 'Taxi Rides']]\n",
    "    for hour, count in sorted(trip_start_hour_counts.items()):\n",
    "        trip_start_hour_table_data.append([hour, count])\n",
    "    \n",
    "    # Convert table data to a DataFrame for distribution of taxi rides by trip start hour\n",
    "    trip_start_hour_df = pd.DataFrame(trip_start_hour_table_data[1:], columns=trip_start_hour_table_data[0])\n",
    "    \n",
    "    # Display the DataFrame for distribution of taxi rides by trip start hour\n",
    "    print(\"Taxi Rides by Hour of the Day (Start Time):\")\n",
    "    print(trip_start_hour_df)\n",
    "    \n",
    "    # Plot the table for distribution of taxi rides by trip start hour\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    ax.axis('off')  # Turn off axis for the table\n",
    "    trip_start_hour_table = ax.table(cellText=trip_start_hour_df.values, colLabels=trip_start_hour_df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2])\n",
    "    trip_start_hour_table.auto_set_font_size(False)\n",
    "    trip_start_hour_table.set_fontsize(12)\n",
    "    trip_start_hour_table.scale(1.5, 1.5)  # Adjust table size\n",
    "    plt.show()\n",
    "    \n",
    "    # Construct a directed graph from pickup and dropoff locations\n",
    "    G = nx.DiGraph()\n",
    "    for record in data:\n",
    "        pickup_location = record[\"Pickup Community Area\"]\n",
    "        dropoff_location = record[\"Dropoff Community Area\"]\n",
    "        if pickup_location != dropoff_location:\n",
    "            G.add_edge(pickup_location, dropoff_location)\n",
    "    \n",
    "    # Calculate degree centrality\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    \n",
    "    # Calculate betweenness centrality\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    \n",
    "    # Calculate PageRank\n",
    "    pagerank = nx.pagerank(G)\n",
    "    \n",
    "    # Calculate clustering coefficient\n",
    "    clustering_coefficient = nx.clustering(G)\n",
    "    \n",
    "    # Create the table data for network metrics\n",
    "    network_metrics_table_data = [['Node', 'Degree Centrality', 'Betweenness Centrality', 'PageRank', 'Clustering Coefficient']]\n",
    "    for node in G.nodes():\n",
    "        network_metrics_table_data.append([node, degree_centrality.get(node, 0), betweenness_centrality.get(node, 0), pagerank.get(node, 0), clustering_coefficient.get(node, 0)])\n",
    "    \n",
    "    # Convert table data to a DataFrame for network metrics\n",
    "    network_metrics_df = pd.DataFrame(network_metrics_table_data[1:], columns=network_metrics_table_data[0])\n",
    "    \n",
    "    # Display the network metrics DataFrame\n",
    "    print(\"Network Metrics:\")\n",
    "    print(network_metrics_df)\n",
    "    \n",
    "    # Plot the table for network metrics\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.axis('off')  # Turn off axis for the table\n",
    "    network_metrics_table = ax.table(cellText=network_metrics_df.values, colLabels=network_metrics_df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    network_metrics_table.auto_set_font_size(False)\n",
    "    network_metrics_table.set_fontsize(12)\n",
    "    network_metrics_table.scale(1.5, 1.5)  # Adjust table size\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting by Sports Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a defaultdict to count taxi rides by season\n",
    "season_counts = defaultdict(int)\n",
    "\n",
    "# Define start and end dates for each major sports season (recurring every year)\n",
    "seasons = {\n",
    "    \"NBA\": {\"start\": (10, 1), \"end\": (4, 30)},\n",
    "    \"MLB\": {\"start\": (3, 1), \"end\": (10, 31)},\n",
    "    \"NFL\": {\"start\": (9, 1), \"end\": (12, 31)},\n",
    "    \"NHL\": {\"start\": (10, 1), \"end\": (4, 30)},\n",
    "    \"MLS\": {\"start\": (2, 1), \"end\": (12, 31)}\n",
    "}\n",
    "\n",
    "# Function to categorize a timestamp into sports seasons\n",
    "def categorize_season(timestamp):\n",
    "    if timestamp:\n",
    "        timestamp = datetime.strptime(timestamp, \"%m/%d/%Y %I:%M:%S %p\")\n",
    "        matched_seasons = []\n",
    "        for sport, dates in seasons.items():\n",
    "            start_month, start_day = dates[\"start\"]\n",
    "            end_month, end_day = dates[\"end\"]\n",
    "            \n",
    "            # Adjust the year for NHL and NBA if the timestamp falls after April\n",
    "            if start_month > end_month and timestamp.month < start_month:\n",
    "                season_start = datetime(timestamp.year - 1, start_month, start_day)\n",
    "                season_end = datetime(timestamp.year, end_month, end_day)\n",
    "            else:\n",
    "                season_start = datetime(timestamp.year, start_month, start_day)\n",
    "                season_end = datetime(timestamp.year, end_month, end_day)\n",
    "            \n",
    "            # Check if the timestamp falls within the season\n",
    "            if season_start <= timestamp <= season_end:\n",
    "                matched_seasons.append(sport)\n",
    "        if matched_seasons:\n",
    "            return matched_seasons\n",
    "    return ['None']  # Return 'None' if no sports season is matched\n",
    "\n",
    "# Sort the data by major sports seasons\n",
    "for record in data:\n",
    "    seasons_matched = categorize_season(record[\"Trip Start Timestamp\"])\n",
    "    for season in seasons_matched:\n",
    "        season_counts[season] += 1\n",
    "\n",
    "# Plot the data as a bar graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(season_counts.keys(), season_counts.values())\n",
    "plt.xlabel(\"Sports Season\")\n",
    "plt.ylabel(\"Number of Taxi Rides\")\n",
    "plt.title(\"Distribution of Taxi Rides by Sports Season\")\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.show()\n",
    "\n",
    "# Create the table data\n",
    "table_data = [['Sports Season', 'Taxi Rides']]\n",
    "for season, count in season_counts.items():\n",
    "    table_data.append([season, count])\n",
    "\n",
    "# Convert table data to a DataFrame\n",
    "df = pd.DataFrame(table_data[1:], columns=table_data[0])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Taxi Rides by Sports Season:\")\n",
    "print(df)\n",
    "\n",
    "# Plot the table\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ax.axis('off')  # Turn off axis for the table\n",
    "\n",
    "# Create the table\n",
    "table = ax.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.5, 1.5)  # Adjust table size\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Construct a directed graph from pickup and dropoff locations\n",
    "G = nx.DiGraph()\n",
    "for record in data:\n",
    "    pickup_location = record[\"Pickup Community Area\"]\n",
    "    dropoff_location = record[\"Dropoff Community Area\"]\n",
    "    if pickup_location != dropoff_location:\n",
    "        G.add_edge(pickup_location, dropoff_location)\n",
    "\n",
    "# Calculate degree centrality\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Calculate betweenness centrality\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "\n",
    "# Calculate PageRank\n",
    "pagerank = nx.pagerank(G)\n",
    "\n",
    "# Calculate clustering coefficient\n",
    "clustering_coefficient = nx.clustering(G)\n",
    "\n",
    "# Create the table data for network metrics\n",
    "network_metrics_table_data = [['Node', 'Degree Centrality', 'Betweenness Centrality', 'PageRank', 'Clustering Coefficient']]\n",
    "for node in G.nodes():\n",
    "    network_metrics_table_data.append([node, degree_centrality.get(node, 0), betweenness_centrality.get(node, 0), pagerank.get(node, 0), clustering_coefficient.get(node, 0)])\n",
    "\n",
    "# Convert table data to a DataFrame for network metrics\n",
    "network_metrics_df = pd.DataFrame(network_metrics_table_data[1:], columns=network_metrics_table_data[0])\n",
    "\n",
    "# Display the network metrics DataFrame\n",
    "print(\"Network Metrics:\")\n",
    "print(network_metrics_df)\n",
    "\n",
    "# Plot the table for network metrics\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.axis('off')  # Turn off axis for the table\n",
    "network_metrics_table = ax.table(cellText=network_metrics_df.values, colLabels=network_metrics_df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "network_metrics_table.auto_set_font_size(False)\n",
    "network_metrics_table.set_fontsize(12)\n",
    "network_metrics_table.scale(1.5, 1.5)  # Adjust table size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting by Day of Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a defaultdict to count taxi rides by day of the week\n",
    "day_of_week_counts = defaultdict(int)\n",
    "\n",
    "# Function to categorize a timestamp into day of the week\n",
    "def categorize_day_of_week(timestamp):\n",
    "    timestamp = datetime.strptime(timestamp, \"%m/%d/%Y %I:%M:%S %p\")\n",
    "    return timestamp.strftime(\"%A\")  # Return the full name of the day of the week\n",
    "\n",
    "# Sort the data by day of the week\n",
    "for record in data:\n",
    "    day_of_week = categorize_day_of_week(record[\"Trip Start Timestamp\"])\n",
    "    day_of_week_counts[day_of_week] += 1\n",
    "\n",
    "# Plot the data as a bar graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(day_of_week_counts.keys(), day_of_week_counts.values())\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel(\"Number of Taxi Rides\")\n",
    "plt.title(\"Distribution of Taxi Rides by Day of the Week\")\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.show()\n",
    "\n",
    "# Create the table data\n",
    "table_data = [['Day of the Week', 'Taxi Rides']]\n",
    "for day, count in day_of_week_counts.items():\n",
    "    table_data.append([day, count])\n",
    "\n",
    "# Convert table data to a DataFrame\n",
    "df = pd.DataFrame(table_data[1:], columns=table_data[0])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Taxi Rides by Day of the Week:\")\n",
    "print(df)\n",
    "\n",
    "# Plot the table\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ax.axis('off')  # Turn off axis for the table\n",
    "\n",
    "# Create the table\n",
    "table = ax.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.5, 1.5)  # Adjust table size\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Construct a directed graph from pickup and dropoff locations\n",
    "G = nx.DiGraph()\n",
    "for record in data:\n",
    "    pickup_location = record[\"Pickup Community Area\"]\n",
    "    dropoff_location = record[\"Dropoff Community Area\"]\n",
    "    if pickup_location != dropoff_location:\n",
    "        G.add_edge(pickup_location, dropoff_location)\n",
    "\n",
    "# Calculate degree centrality\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Calculate betweenness centrality\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "\n",
    "# Calculate PageRank\n",
    "pagerank = nx.pagerank(G)\n",
    "\n",
    "# Calculate clustering coefficient\n",
    "clustering_coefficient = nx.clustering(G)\n",
    "\n",
    "# Create the table data for network metrics\n",
    "network_metrics_table_data = [['Node', 'Degree Centrality', 'Betweenness Centrality', 'PageRank', 'Clustering Coefficient']]\n",
    "for node in G.nodes():\n",
    "    network_metrics_table_data.append([node, degree_centrality.get(node, 0), betweenness_centrality.get(node, 0), pagerank.get(node, 0), clustering_coefficient.get(node, 0)])\n",
    "\n",
    "# Convert table data to a DataFrame for network metrics\n",
    "network_metrics_df = pd.DataFrame(network_metrics_table_data[1:], columns=network_metrics_table_data[0])\n",
    "\n",
    "# Display the network metrics DataFrame\n",
    "print(\"Network Metrics:\")\n",
    "print(network_metrics_df)\n",
    "\n",
    "# Plot the table for network metrics\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.axis('off')  # Turn off axis for the table\n",
    "network_metrics_table = ax.table(cellText=network_metrics_df.values, colLabels=network_metrics_df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "network_metrics_table.auto_set_font_size(False)\n",
    "network_metrics_table.set_fontsize(12)\n",
    "network_metrics_table.scale(1.5, 1.5)  # Adjust table size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting by Top 20 Pickup Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a defaultdict to count taxi rides by pick up location\n",
    "pickup_counts = defaultdict(int)\n",
    "\n",
    "# Function to categorize a trip by pick up location\n",
    "def categorize_pickup_location(pickup_location):\n",
    "    return pickup_location\n",
    "\n",
    "# Sort the data by pick up location and count occurrences\n",
    "for record in data:\n",
    "    pickup_location = record[\"Pickup Community Area\"]\n",
    "    pickup_counts[pickup_location] += 1\n",
    "\n",
    "# Sort the pickup counts dictionary by values in descending order\n",
    "sorted_pickup_counts = dict(sorted(pickup_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Select only the top 20 pick up locations\n",
    "top_20_pickup_locations = dict(list(sorted_pickup_counts.items())[:20])\n",
    "\n",
    "# Plot the data as a bar graph for top 20 pickup locations\n",
    "plt.figure(figsize=(10, 6))  # Adjust figsize as needed\n",
    "plt.bar(top_20_pickup_locations.keys(), top_20_pickup_locations.values())\n",
    "plt.xlabel(\"Pick Up Location\")\n",
    "plt.ylabel(\"Number of Taxi Rides\")\n",
    "plt.title(\"Top 20 Pick Up Locations\")\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "plt.show()\n",
    "\n",
    "# Create the table data\n",
    "table_data = [['Pick Up Location', 'Taxi Rides']]\n",
    "for location, count in top_20_pickup_locations.items():\n",
    "    table_data.append([location, count])\n",
    "\n",
    "# Convert table data to a DataFrame\n",
    "df = pd.DataFrame(table_data[1:], columns=table_data[0])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Top 20 Pick Up Locations:\")\n",
    "print(df)\n",
    "\n",
    "# Plot the table\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "ax.axis('off')  # Turn off axis for the table\n",
    "\n",
    "# Create the table\n",
    "table = ax.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.5, 1.5)  # Adjust table size\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Construct a directed graph from pickup and dropoff locations\n",
    "G = nx.DiGraph()\n",
    "for record in data:\n",
    "    pickup_location = record[\"Pickup Community Area\"]\n",
    "    dropoff_location = record[\"Dropoff Community Area\"]\n",
    "    if pickup_location != dropoff_location:\n",
    "        G.add_edge(pickup_location, dropoff_location)\n",
    "\n",
    "# Calculate degree centrality\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Calculate betweenness centrality\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "\n",
    "# Calculate PageRank\n",
    "pagerank = nx.pagerank(G)\n",
    "\n",
    "# Calculate clustering coefficient\n",
    "clustering_coefficient = nx.clustering(G)\n",
    "\n",
    "# Create the table data for network metrics\n",
    "network_metrics_table_data = [['Node', 'Degree Centrality', 'Betweenness Centrality', 'PageRank', 'Clustering Coefficient']]\n",
    "for node in G.nodes():\n",
    "    network_metrics_table_data.append([node, degree_centrality.get(node, 0), betweenness_centrality.get(node, 0), pagerank.get(node, 0), clustering_coefficient.get(node, 0)])\n",
    "\n",
    "# Convert table data to a DataFrame for network metrics\n",
    "network_metrics_df = pd.DataFrame(network_metrics_table_data[1:], columns=network_metrics_table_data[0])\n",
    "\n",
    "# Display the network metrics DataFrame\n",
    "print(\"Network Metrics:\")\n",
    "print(network_metrics_df)\n",
    "\n",
    "# Plot the table for network metrics\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.axis('off')  # Turn off axis for the table\n",
    "network_metrics_table = ax.table(cellText=network_metrics_df.values, colLabels=network_metrics_df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "network_metrics_table.auto_set_font_size(False)\n",
    "network_metrics_table.set_fontsize(12)\n",
    "network_metrics_table.scale(1.5, 1.5)  # Adjust table size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting by Top 20 Drop-Off Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a defaultdict to count taxi rides by drop off location\n",
    "dropoff_counts = defaultdict(int)\n",
    "\n",
    "# Function to categorize a trip by drop off location\n",
    "def categorize_dropoff_location(dropoff_location):\n",
    "    return dropoff_location\n",
    "\n",
    "# Sort the data by drop off location and count occurrences\n",
    "for record in data:\n",
    "    dropoff_location = record[\"Dropoff Community Area\"]\n",
    "    dropoff_counts[dropoff_location] += 1\n",
    "\n",
    "# Sort the dropoff counts dictionary by values in descending order\n",
    "sorted_dropoff_counts = dict(sorted(dropoff_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Select only the top 20 drop-off locations\n",
    "top_20_dropoff_locations = dict(list(sorted_dropoff_counts.items())[:20])\n",
    "\n",
    "# Plot the data as a bar graph for top 20 drop-off locations\n",
    "plt.figure(figsize=(10, 6))  # Adjust figsize as needed\n",
    "plt.bar(top_20_dropoff_locations.keys(), top_20_dropoff_locations.values())\n",
    "plt.xlabel(\"Drop Off Location\")\n",
    "plt.ylabel(\"Number of Taxi Rides\")\n",
    "plt.title(\"Top 20 Drop Off Locations\")\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "plt.show()\n",
    "\n",
    "# Create the table data\n",
    "table_data = [['Drop Off Location', 'Taxi Rides']]\n",
    "for location, count in top_20_dropoff_locations.items():\n",
    "    table_data.append([location, count])\n",
    "\n",
    "# Convert table data to a DataFrame\n",
    "df = pd.DataFrame(table_data[1:], columns=table_data[0])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Top 20 Drop Off Locations:\")\n",
    "print(df)\n",
    "\n",
    "# Plot the table\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "ax.axis('off')  # Turn off axis for the table\n",
    "\n",
    "# Create the table\n",
    "table = ax.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.5, 1.5)  # Adjust table size\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Construct a directed graph from pickup and dropoff locations\n",
    "G = nx.DiGraph()\n",
    "for record in data:\n",
    "    pickup_location = record[\"Pickup Community Area\"]\n",
    "    dropoff_location = record[\"Dropoff Community Area\"]\n",
    "    if pickup_location != dropoff_location:\n",
    "        G.add_edge(pickup_location, dropoff_location)\n",
    "\n",
    "# Calculate degree centrality\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Calculate betweenness centrality\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "\n",
    "# Calculate PageRank\n",
    "pagerank = nx.pagerank(G)\n",
    "\n",
    "# Calculate clustering coefficient\n",
    "clustering_coefficient = nx.clustering(G)\n",
    "\n",
    "# Create the table data for network metrics\n",
    "network_metrics_table_data = [['Node', 'Degree Centrality', 'Betweenness Centrality', 'PageRank', 'Clustering Coefficient']]\n",
    "for node in G.nodes():\n",
    "    network_metrics_table_data.append([node, degree_centrality.get(node, 0), betweenness_centrality.get(node, 0), pagerank.get(node, 0), clustering_coefficient.get(node, 0)])\n",
    "\n",
    "# Convert table data to a DataFrame for network metrics\n",
    "network_metrics_df = pd.DataFrame(network_metrics_table_data[1:], columns=network_metrics_table_data[0])\n",
    "\n",
    "# Display the network metrics DataFrame\n",
    "print(\"Network Metrics:\")\n",
    "print(network_metrics_df)\n",
    "\n",
    "# Plot the table for network metrics\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.axis('off')  # Turn off axis for the table\n",
    "network_metrics_table = ax.table(cellText=network_metrics_df.values, colLabels=network_metrics_df.columns, loc='center', cellLoc='center', colWidths=[0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "network_metrics_table.auto_set_font_size(False)\n",
    "network_metrics_table.set_fontsize(12)\n",
    "network_metrics_table.scale(1.5, 1.5)  # Adjust table size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickup and Dropoff Flow Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize a defaultdict to count taxi rides by pick up and drop off location\n",
    "pickup_counts = defaultdict(int)\n",
    "dropoff_counts = defaultdict(int)\n",
    "\n",
    "# Sort the data by pick up and drop off location and count occurrences\n",
    "for record in data:\n",
    "    pickup_location = record[\"Pickup Community Area\"]\n",
    "    dropoff_location = record[\"Dropoff Community Area\"]\n",
    "    if pickup_location:\n",
    "        pickup_counts[pickup_location] += 1\n",
    "    if dropoff_location:\n",
    "        dropoff_counts[dropoff_location] += 1\n",
    "\n",
    "# Construct a directed graph for pickup and drop-off locations\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes \"Source\" and \"Target\" to the graph\n",
    "G.add_node(\"Source\")\n",
    "G.add_node(\"Target\")\n",
    "\n",
    "# Add edges for pickup locations\n",
    "for pickup_location in pickup_counts.keys():\n",
    "    G.add_edge(\"Source\", pickup_location, capacity=pickup_counts[pickup_location])\n",
    "\n",
    "# Add edges for drop-off locations\n",
    "for dropoff_location in dropoff_counts.keys():\n",
    "    G.add_edge(dropoff_location, \"Target\", capacity=dropoff_counts[dropoff_location])\n",
    "\n",
    "# Calculate the maximum flow from source to target\n",
    "flow_value, flow_dict = nx.maximum_flow(G, \"Source\", \"Target\")\n",
    "\n",
    "# Display the flow values\n",
    "print(\"Flow from source to pickup locations:\")\n",
    "for pickup_location, flow in flow_dict[\"Source\"].items():\n",
    "    print(f\"{pickup_location}: {flow}\")\n",
    "\n",
    "# Display the flow values for drop-off locations\n",
    "print(\"\\nFlow from drop-off locations to target:\")\n",
    "for dropoff_location in flow_dict:\n",
    "    if dropoff_location != \"Source\":\n",
    "        flow_to_target = sum(flow_dict[dropoff_location].values())\n",
    "        print(f\"{dropoff_location}: {flow_to_target}\")\n",
    "\n",
    "# Visualize the flow graphically\n",
    "pos = nx.spring_layout(G)  # Position nodes using Fruchterman-Reingold force-directed algorithm\n",
    "nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=500, font_size=10, arrows=True)\n",
    "edge_labels = nx.get_edge_attributes(G, 'capacity')  # Get edge labels (capacity)\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)  # Draw edge labels\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
